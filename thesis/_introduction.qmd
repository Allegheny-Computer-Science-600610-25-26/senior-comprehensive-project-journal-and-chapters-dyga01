# Introduction

This research introduces a tool called Vurze.[@vurze] Vurze, short for “version control,” is a command-line tool that enforces cryptographic integrity for Python functions and classes by automatically injecting decorators. Each decorator is a cryptographic signature that represents the unerlying source code. To generate this signature, Vurze uses a private key along with the function’s source code. If even a single character in the code changes, the resulting signature will differ completely, allowing the detection of any unauthorized modifications.

At a high level, Vurze introduces a novel approach to source control by enabling code to version-control other code. Instead of relying solely on external files that store version histories, Vurze embeds decorators directly within the source code itself. This per-entity approach is, in some ways, less complex than traditional version control systems and is designed to complement them. Traditional version control systems like Git rely on hidden files to record changes across an entire codebase.[@git] While this approach is highly effective for large-scale version management and collaboration, it treats code as a collection of files rather than individual, verifiable entities. Vurze complements this model by introducing built-in, function-level verification that provides an additional layer of security against unauthorized modifications.

The Vurze tool provides a simple command-line interface (CLI) with commands to initialize keys, add decorators, verify signatures, and remove decorators. The CLI is intentionally minimalist so it can be easily integrated into CI/CD pipelines, invoked as a pre-deployment check, or used within middleware. Vurze is built with both Python and Rust to combine Python’s flexibility with Rust’s performance and safety. Rust also offers robust built-in libraries for cryptography, making it an ideal foundation for secure and efficient code execution.

## Motivation

### Model Context Protocol

This research is motivated by security concerns surrounding Anthropic's newly released Model Context Protocol (MCP).[@model-context-protocol] MCP is a system that provides a standardized interface for managing the context that large language models (LLMs) access. MCP also allows LLMs to connect to external systems such as APIs, databases, and local filesystems. While MCP introduces powerful capabilities for building cusomized AI applications, sometimes known as AI agents, it also creates new attack surfaces.

Model Context Protocol operates through a client-server architecture. MCP clients are applications that host LLMs such as Claude Desktop, Integrated Development Enironments, or other custom AI applications. MCP servers are lightweight programs that expose specific capabilities such as database access, file system operations, or API integrations—to these clients through a standardized interface. When a user interacts with an MCP client, the LLM can request the client to invoke functions on connected MCP servers, effectively extending the LLM's capabilities beyond its training data.

In order to help the MCP client understand what capabilities are available, MCP servers expose tools that describe their purpose and parameters. Tools are essentially functions that the LLM can interpret and invoke. The LLM relies on these tool descriptions, held in docstrings, to decide when and how to invoke each tool. For example, a tool with the docstring "Send an email to a recipient" informs the LLM that this function should be called when the user asks to send an email. The LLM never sees the actual implementation code; it only sees the tool's name, description, and parameter schema.

![MCP Architecture Diagram](images/mcp-overall-diagram.png)

### Tool Poisoning Attacks

The Model Context Protocol architecture introduces a significant attack surface through its reliance on tool descriptions for interactions with LLMs. A Tool Poisoning Attack can occur when threat actors embed malicious instructions within the docstrings of MCP tools.[@invariant-labs-tool-poisoning] These instructions are crafted to be invisible to end users, who typically see only a simplified version of the tool description in their UI. However, LLMs always see the full docstring and can be manipulated into performing unauthorized or harmful actions.

This vulnerability exists because the LLM’s decision-making process relies exclusively on the tool descriptions it receives, which may contain hidden directions. These hidden directions can prompt the LLM to perform malicious actions, such as silently leaking sensitive data or executing unintended commands.

To demonstrate a Tool Poisoning Attack (TPA), an example MCP server was created that submits customer support tickets. In this scenario, malicious instructions are embedded within the tool's docstring, specifically targeting the behavior of the LLM. These instructions direct the LLM to read the contents of a sensitive file (`~/.ssh/id_rsa`), which contains a private SSH key. The LLM is then instructed to pass this data as a `sidenote` argument when invoking the tool. Finally, the instructions require the model to conceal this action from the user, instead providing plausible reasoning for using the tool.

![Tool Poisoning Attack Code](images/tool-poisoning-attack-code.png)

### Tool Shadowing Attacks

This architecture also creates attack surfaces related to tool descriptions as there is currently no mechanism to verify whether tool descriptions have context overlap. Whenever two MCP tool docstrings contain similar keywords and intent, the ____ may not know ______. This creates a critical vulnerability

add diagram here

This architecture creates attack surfaces related to tool descriptions as there is currently no mechanism to verify whether tool descriptions have context overlap. Whenever two MCP tool docstrings contain similar keywords and intent, the LLM may not know which tool to invoke or may use context from both tools but only invoke one.

This creates a critical vulnerability where a malicious MCP server can register tools with descriptions that deliberately shadow legitimate tools from trusted servers.

In a tool shadowing attack, an adversary creates an MCP server with tool descriptions crafted to match the semantic intent of legitimate tools. When a user requests an action that matches both the legitimate and malicious tool descriptions, the LLM must choose between them based solely on the textual similarity between the user's request and the available tool descriptions. Because the LLM has no information about tool provenance, security boundaries, or trust relationships between servers, it cannot distinguish between a legitimate tool and its malicious shadow.

The impact of successful tool shadowing attacks can be severe. A malicious tool that shadows a legitimate email-sending function could exfiltrate sensitive data by copying messages to an attacker-controlled address. A shadowed database query tool could leak confidential information or execute unauthorized modifications. File system tools could be shadowed to enable data theft or system compromise. The fundamental issue is that the LLM treats all tools as equally trustworthy based purely on their descriptions, with no concept of server reputation, security policies, or user-defined trust boundaries.

is cross server tool shadowing possible

example figure label here:

## Current State of the Art

add sources before starting this
mcp security from a high level perspective.
currently no tool exhists that is similar tools
mcp security tools for preventing tool shadowing attacks

Table: A two-row table demonstrating tables

|Row number | Description |
|:----------|:------------|
|1          |Row 1        |
|2          |Row 2        |

## Goals of the Project

detect and prevent x attacks
how does vurze plan to solve this attack. 
what does success look like for this
in addition to potential upstream attacks that vurze, would prevent. propose using vurze to only add signatures to trusted functions. this functions as a version control system specific to mcp servers
how do i connect version control to what descriptions say

## Ethical Implications

mcp servers are being increasingly adopted, so x
if someone were to start a malicious server, i understand that there are some potential issues

This document requires that you discuss the ethical implications of your work -- no
matter how benign you consider the outcome of your project. As several major studies
of ethical issues in computer science assert: _no project is completely value-neutral_.

To assist you in elaborating on these issues, the following areas are topics you might
consider addressing. You do not need to address all of them.

* Information Privacy
* Information Accuracy (e.g. can contain reliability)
* Potential Misuse (e.g. computer crime, unintended consequences)
* Second- or Third-Party Risk (e.g. safety)
* Data Collection Issues (e.g. issues inherent in collecting data)
* Algorithmic or Data Bias
* Potential Power Difference / Social Imbalance / Issues in Equity

In addition, reflect on ways that the above harms can be or are mitigated by your work.
