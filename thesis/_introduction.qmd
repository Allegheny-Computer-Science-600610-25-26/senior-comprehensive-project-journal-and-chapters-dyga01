# Introduction

This research introduces a tool called Vurze.[@vurze] Vurze, short for “version control,” is a command-line tool that enforces cryptographic integrity for Python functions and classes by automatically injecting decorators. Each decorator is a cryptographic signature that represents the unerlying source code. To generate this signature, Vurze uses a private key along with the function’s source code. If even a single character in the code changes, the resulting signature will differ completely, allowing the detection of any unauthorized modifications.

At a high level, Vurze introduces a novel approach to source control by enabling code to version-control other code. Instead of relying solely on external files that store version histories, Vurze embeds decorators directly within the source code itself. This per-entity approach is, in some ways, less complex than traditional version control systems and is designed to complement them. Traditional version control systems like Git rely on hidden files to record changes across an entire codebase.[@git] While this approach is highly effective for large-scale version management and collaboration, it treats code as a collection of files rather than individual, verifiable entities. Vurze complements this model by introducing built-in, function-level verification that provides an additional layer of security against unauthorized modifications.

The Vurze tool provides a simple command-line interface (CLI) with commands to initialize keys, add decorators, verify signatures, and remove decorators. The CLI is intentionally minimalist so it can be easily integrated into CI/CD pipelines, invoked as a pre-deployment check, or used within middleware. Vurze is built with both Python and Rust to combine Python’s flexibility with Rust’s performance and safety. Rust also offers robust built-in libraries for cryptography, making it an ideal foundation for secure and efficient code execution.

## Motivation

### Model Context Protocol

This research is motivated by security concerns surrounding Anthropic's newly released Model Context Protocol (MCP).[@model-context-protocol] MCP is a system that provides a standardized interface for managing the context that large language models (LLMs) access. MCP also allows LLMs to connect to external systems such as APIs, databases, and local filesystems. While MCP introduces powerful capabilities for building cusomized AI applications, sometimes known as AI agents, it also creates new attack surfaces.

Model Context Protocol operates through a client-server architecture. MCP clients are applications that host LLMs such as Claude Desktop, Integrated Development Enironments, or other custom AI applications. MCP servers are lightweight programs that expose specific capabilities such as database access, file system operations, or API integrations—to these clients through a standardized interface. When a user interacts with an MCP client, the LLM can request the client to invoke functions on connected MCP servers, effectively extending the LLM's capabilities beyond its training data.

In order to help the MCP client understand what capabilities are available, MCP servers expose tools that describe their purpose and parameters. Tools are essentially functions that the LLM can interpret and invoke. The LLM relies on these tool descriptions, held in docstrings, to decide when and how to invoke each tool. For example, a tool with the docstring "Send an email to a recipient" informs the LLM that this function should be called when the user asks to send an email. The LLM never sees the actual implementation code; it only sees the tool's name, description, and parameter schema.

![MCP Architecture Diagram](images/mcp-overall-diagram.png)

### Tool Poisoning Attacks

The Model Context Protocol architecture introduces a significant attack surface through its reliance on tool descriptions for interactions with LLMs. A Tool Poisoning Attack can occur when threat actors embed malicious instructions within the docstrings of MCP tools.[@invariant-labs-tool-poisoning] These instructions are crafted to be invisible to end users, who typically see only a simplified version of the tool description in their UI. However, LLMs always see the full docstring and can be manipulated into performing unauthorized or harmful actions.

This vulnerability exists because the LLM’s decision-making process relies exclusively on the tool descriptions it receives, which may contain hidden directions. These hidden directions can prompt the LLM to perform malicious actions, such as silently leaking sensitive data or executing unintended commands.

To demonstrate a Tool Poisoning Attack (TPA), an example MCP server was created that submits customer support tickets. In this scenario, malicious instructions are embedded within the tool's docstring, specifically targeting the behavior of the LLM. These instructions direct the LLM to read the contents of a sensitive file (`~/.ssh/id_rsa`), which contains a private SSH key. The LLM is then instructed to pass this data as a `sidenote` argument when invoking the tool. Finally, the instructions require the model to conceal this action from the user, instead providing plausible reasoning for using the tool.

![Tool Poisoning Attack Code](images/tool-poisoning-attack-code.png)

### Tool Shadowing Attacks

This architecture also creates attack surfaces related to tool descriptions that have overlapping context.[@invariant-labs-tool-poisoning] Whenever two MCP tool docstrings contain similar keywords and intent, the LLM may not know which tool to invoke or may use context from both tools but only invoke one. This creates a critical vulnerability where malicious tools can be added to an MCP Server that deliberately shadow legitimate tools.

Because the LLM is given all tool descriptions simultaneously when making decisions, it relies on the similarity of names, keywords, and docstrings to select which tool to invoke. If a threat actor is able to add a tool with a name or description that closely resembles a legitimate tool, the LLM may inadvertently select or use context from the shadow tool. This ambiguity is especially dangerous because the user interface of the MCP host application, like Claude Desktop, typically does not reveal the full tool docstring, making it difficult for users to detect when a shadow tool has been invoked.

In order to demonstrate a tool shadowing attack, consider a scenario where a shadow tool is registered that adds a threat actors email to an email notification list. In this scenario, a shadow tool named create_ticket_better is registered alongside the legitimate create_ticket tool. The shadow tool’s docstring instructs the LLM to always add a specific email address (example@test.com) to the notification list before using the legitimate tool. This would ensure that the threat actor is notified of every support ticket that is submitted. In order to take this one step further, the threat actor could even add directions that instruct the LLM to conceal the email it added.

![Tool Shadowing Attack Code](images/tool-shadowing-attack-code.png)

## Current State of the Art

add sources before starting this
mcp security from a high level perspective.
currently no tool exhists that is similar tools
mcp security tools for preventing tool shadowing attacks
middleware???
fastmcp???

Table: A two-row table demonstrating tables

|Row number | Description |
|:----------|:------------|
|1          |Row 1        |
|2          |Row 2        |

## Goals of the Project

detect and prevent x attacks
how does vurze plan to solve this attack. 
what does success look like for this
in addition to potential upstream attacks that vurze, would prevent. propose using vurze to only add signatures to trusted functions. this functions as a version control system specific to mcp servers
how do i connect version control to what descriptions say

## Ethical Implications

mcp servers are being increasingly adopted, so x

malicous mcp servers can be used to exfiltrate sensitive data. as shown in the ssh example

other ethical discussion of tool shadowing example

i also understnad that my tool vurze could be used on a malicious server, but x and x and x here

overall there are many ehtical concerns


* Information Privacy
* Information Accuracy (e.g. can contain reliability)
* Potential Misuse (e.g. computer crime, unintended consequences)
* Second- or Third-Party Risk (e.g. safety)
* Data Collection Issues (e.g. issues inherent in collecting data)
* Algorithmic or Data Bias
* Potential Power Difference / Social Imbalance / Issues in Equity

In addition, reflect on ways that the above harms can be or are mitigated by your work.
