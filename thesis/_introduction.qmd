# Introduction

This research introduces a tool called Vurze.[@vurze] Vurze, short for “version control,” is a command-line tool that enforces cryptographic integrity for Python functions and classes by automatically injecting decorators. Each decorator is a cryptographic signature that represents the unerlying source code. To generate this signature, Vurze uses a private key along with the function’s source code. If even a single character in the code changes, the resulting signature will differ completely, allowing the detection of any unauthorized modifications.

At a high level, Vurze introduces a novel approach to source control by enabling code to version-control other code. Instead of relying solely on external files that store version histories, Vurze embeds decorators directly within the source code itself. This per-entity approach is, in some ways, less complex than traditional version control systems and is designed to complement them. Traditional version control systems like Git rely on hidden files to record changes across an entire codebase.[@git] While this approach is highly effective for large-scale version management and collaboration, it treats code as a collection of files rather than individual, verifiable entities. Vurze complements this model by introducing built-in, function-level verification that provides an additional layer of security against unauthorized modifications.

The Vurze tool provides a simple command-line interface (CLI) with commands to initialize keys, add decorators, verify signatures, and remove decorators. The CLI is intentionally minimalist so it can be easily integrated into CI/CD pipelines, invoked as a pre-deployment check, or used within middleware. Vurze is built with both Python and Rust to combine Python’s flexibility with Rust’s performance and safety. Rust also offers robust built-in libraries for cryptography, making it an ideal foundation for secure and efficient code execution.

## Motivation

### Model Context Protocol (MCP)

This research is motivated by security concerns surrounding Anthropic's newly released Model Context Protocol (MCP).[@model-context-protocol] MCP is a system that provides a standardized interface for managing the context that large language models (LLMs) access. MCP also allows LLMs to connect to external systems such as APIs, databases, and local filesystems. While MCP introduces powerful capabilities for building cusomized AI applications, sometimes known as AI agents, it also creates new attack surfaces.

Model Context Protocol operates through a client-server architecture. MCP clients are applications that host LLMs such as Claude Desktop, Integrated Development Enironments, or other custom AI applications. MCP servers are lightweight programs that expose specific capabilities such as database access, file system operations, or API integrations—to these clients through a standardized interface. When a user interacts with an MCP client, the LLM can request the client to invoke functions on connected MCP servers, effectively extending the LLM's capabilities beyond its training data.

In order to help the MCP client understand what capabilities are available, MCP servers expose tools that describe their purpose and parameters. Tools are essentially functions that the LLM can interpret and invoke. The LLM relies on these tool descriptions, held in docstrings, to decide when and how to invoke each tool. For example, a tool with the docstring "Send an email to a recipient" informs the LLM that this function should be called when the user asks to send an email. The LLM never sees the actual implementation code; it only sees the tool's name, description, and parameter schema.

![MCP Architecture Diagram](images/mcp-overall-diagram.png)

### Tool Poisoning Attacks

The Model Context Protocol architecture introduces a significant attack surface through its reliance on tool descriptions for interactions with LLMs. A Tool Poisoning Attack can occur when threat actors embed malicious instructions within the docstrings of MCP tools.[@invariant-labs-tool-poisoning] These instructions are crafted to be invisible to end users, who typically see only a simplified version of the tool description in their UI. However, LLMs always see the full docstring and can be manipulated into performing unauthorized or harmful actions.

This vulnerability exists because the LLM’s decision-making process relies exclusively on the tool descriptions it receives, which may contain hidden directions. These hidden directions can prompt the LLM to perform malicious actions, such as silently leaking sensitive data or executing unintended commands.

To demonstrate a Tool Poisoning Attack (TPA), an example MCP server was created that submits customer support tickets. In this scenario, malicious instructions are embedded within the tool's docstring, specifically targeting the behavior of the LLM. These instructions direct the LLM to read the contents of a sensitive file (`~/.ssh/id_rsa`), which contains a private SSH key. The LLM is then instructed to pass this data as a `sidenote` argument when invoking the tool. Finally, the instructions require the model to conceal this action from the user, instead providing plausible reasoning for using the tool.

![Tool Poisoning Attack Code](images/tool-poisoning-attack-code.png)

### Tool Shadowing Attacks

This architecture also creates attack surfaces related to tool descriptions that have overlapping context.[@invariant-labs-tool-poisoning] Whenever two MCP tool docstrings contain similar keywords and intent, the LLM may not know which tool to invoke or may use context from both tools but only invoke one. This creates a critical vulnerability where malicious tools can be added to an MCP Server that deliberately shadow legitimate tools.

Because the LLM is given all tool descriptions simultaneously when making decisions, it relies on the similarity of names, keywords, and docstrings to select which tool to invoke. If a threat actor is able to add a tool with a name or description that closely resembles a legitimate tool, the LLM may inadvertently select or use context from the shadow tool. This ambiguity is especially dangerous because the user interface of the MCP host application, like Claude Desktop, typically does not reveal the full tool docstring, making it difficult for users to detect when a shadow tool has been invoked.

In order to demonstrate a tool shadowing attack, consider a scenario where a shadow tool is registered that adds a threat actors email to an email notification list. In this scenario, a shadow tool named create_ticket_better is registered alongside the legitimate create_ticket tool. The shadow tool’s docstring instructs the LLM to always add a specific email address (example@test.com) to the notification list before using the legitimate tool. This would ensure that the threat actor is notified of every support ticket that is submitted. In order to take this one step further, the threat actor could even add directions that instruct the LLM to conceal the email it added.

![Tool Shadowing Attack Code](images/tool-shadowing-attack-code.png)

## Current State of the Art

### MCP Security Landscape

Because MCP was only recently released, much of its attack surfaces have not been fully explored yet. Although research is limited, a small but growing body of work has begun to outline the types of attacks MCP systems may be vulnerable to. Such research finds that MCP systems can be susceptible to attacks during their creation, deployment, operation, and maintenance.[@mcp-landscape-2025] These vulnerabilities can span from both the client and server side of the MCP ecosystem.

Other studies have further explored these risks by actually implementing different attack methods. In fact, the Systematic Analysis of MCP Security paper systematically categorizes and implements 31 distinct attack methods.[@mcp-systematic-2025] The paper introduces an MCP Attack Library (MCPLIB) which includes attacks that fall under four key classifications: direct tool injection, indirect tool injection, malicious user attacks, and LLM inherent attacks. Through quantitative experiments, the study demonstrates that MCP systems are highly susceptible to blind reliance on tool descriptions. In turn, these findings highlight the urgent need for robust defense strategies in the validation of MCP-based ecosystems.

Overall, the evolving MCP security landscape underscores the urgent need for robust defense strategies accross common attack surfaces. Much of the current research focuses on identifying where MCP is most susceptible, developing benchmarking systems for systematic vulnerability assessment, and designing tools that can detect and mitigate attacks in real time.

### MCP Security Benchmarks

Additional research has focused on creating benchmarking systems for evaluating the security of both MCP clients and servers. MCPSecBench, a comprehensive security benchmark and playground, integrates prompt datasets, MCP servers, MCP clients, attack scripts, and protection mechanisms to evaluate attacks across multiple MCP hosts. The benchmark is modular and extensible, allowing researchers to incorporate custom implementations of clients, servers, and transport protocols for systematic security assessment.[@mcpsecbench-2025]

While it is essential to keep these benchmarking systems up to date and continually enhance their coverage, platforms like MCPSecBench primarily serve as tools for prevention and systematic assessment rather than real-time threat detection. Additionally, there is a risk that threat actors may exploit these benchmarks to test and refine their own malicious code, potentially evading detection by current security measures.

Other research presents an MCP Security Benchmark (MSB) system that acts as an end-to-end benchmarking suite. The goal of MSB is to evaluate MCP robustness across the entire tool-use pipeline, including task planning, tool invocation, and response handling.[@mcpsecuritybench-2025] A key difference between MSB and other MCP benchmarking systems is that MSB introduces a Net Resilient Performance (NRP) metric which quantifies the trade-off between an agent’s security and its operational performance.

The results of MSB reveal an interesting relationship between model performance and vulnerability: agents that excel in tool calling and instruction following are paradoxically more susceptible to sophisticated attacks. This is because their advanced capabilities make them more likely to execute malicious instructions embedded in the MCP pipeline. 

### MCP Security Tools

https://github.com/invariantlabs-ai/mcp-scan --> invariant labs tool that scans for attacks including tool poisoning
https://arxiv.org/pdf/2504.12757 --> MCP GUARDIAN: A SECURITY-FIRST LAYER FOR SAFEGUARDING MCP-BASED AI SYSTEM
Akto.io or some other ones
DO NOT GO IN DEPTH HERE 
SHOULD I PUT THIS BEFORE MOTIVATION?   

## Goals of the Project

detect and prevent x attacks
how does vurze plan to solve this attack. 
what does success look like for this
in addition to potential upstream attacks that vurze, would prevent. propose using vurze to only add signatures to trusted functions. this functions as a version control system specific to mcp servers
how do i connect version control to what descriptions say

## Ethical Implications

mcp servers are being increasingly adopted, so xhttps://github.com/mcp?utm_source=blog-source&utm_campaign=mcp-registry-server-launch-2025 --> github mcp registry

malicous mcp servers can be used to exfiltrate sensitive data. as shown in the ssh example

other ethical discussion of tool shadowing example

i also understnad that my tool vurze could be used on a malicious server, but x and x and x here

overall there are many ehtical concerns


* Information Privacy
* Information Accuracy (e.g. can contain reliability)
* Potential Misuse (e.g. computer crime, unintended consequences)
* Second- or Third-Party Risk (e.g. safety)
* Data Collection Issues (e.g. issues inherent in collecting data)
* Algorithmic or Data Bias
* Potential Power Difference / Social Imbalance / Issues in Equity

In addition, reflect on ways that the above harms can be or are mitigated by your work.
